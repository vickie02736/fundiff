I0121 02:45:45.747707 139658891699264 checkpoint_manager.py:709] [process=0][thread=MainThread] CheckpointManager init: checkpointers=None, item_names=None, item_handlers=None, handler_registry=None
I0121 02:45:45.748272 139658891699264 composite_checkpoint_handler.py:505] Initialized registry DefaultCheckpointHandlerRegistry({('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7f04da86df30>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7f04da86df30>}).
I0121 02:45:45.748817 139658891699264 abstract_checkpointer.py:35] orbax-checkpoint version: 0.11.32
I0121 02:45:45.749039 139658891699264 async_checkpointer.py:177] [process=0][thread=MainThread] Using barrier_sync_fn: <function get_barrier_sync_fn.<locals>.<lambda> at 0x7f04da83e170> timeout: 600 secs and primary_host=0 for async checkpoint writes
I0121 02:45:45.751141 139658891699264 checkpoint_manager.py:1818] Found 0 checkpoint steps in /autodl-fs/data/fundiff/burgers/diffusion/FAE_use_pde_True/ckpt
I0121 02:45:45.751557 139658891699264 checkpoint_manager.py:929] [process=0][thread=MainThread] CheckpointManager created,  primary_host=0, CheckpointManagerOptions=CheckpointManagerOptions(save_interval_steps=1, max_to_keep=1, keep_time_interval=None, keep_period=None, should_keep_fn=None, best_fn=None, best_mode='max', keep_checkpoints_without_metrics=True, step_prefix=None, step_format_fixed_length=None, step_name_format=None, create=True, cleanup_tmp_directories=False, save_on_steps=frozenset(), single_host_load_and_broadcast=False, todelete_subdir=None, todelete_full_path=None, enable_background_delete=False, read_only=False, enable_async_checkpointing=True, async_options=None, multiprocessing_options=MultiprocessingOptions(primary_host=0, active_processes=None, barrier_sync_key_prefix=None), should_save_fn=None, file_options=FileOptions(path_permission_mode=None), save_root_metadata=True, temporary_path_class=None, save_decision_policy=None, preservation_policy=None, prevent_write_metrics=False, enable_should_save_is_saving_in_progress_check=True, enable_per_process_directory_creation=False, lightweight_initialize=False), root_directory=/autodl-fs/data/fundiff/burgers/diffusion/FAE_use_pde_True/ckpt: <orbax.checkpoint.checkpoint_manager.CheckpointManager object at 0x7f04dab533a0>
/root/miniconda3/envs/fundiff_env/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
Traceback (most recent call last):
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1275, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 541, in rebuild_storage_fd
    fd = df.detach()
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/autodl-fs/data/fundiff/burgers/diffusion/main.py", line 41, in <module>
    app.run(main)
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/site-packages/absl/app.py", line 316, in run
    _run_main(main, args)
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/site-packages/absl/app.py", line 261, in _run_main
    sys.exit(main(argv))
  File "/autodl-fs/data/fundiff/burgers/diffusion/main.py", line 30, in main
    train_autoencoder.train_and_evaluate(FLAGS.config)
  File "/autodl-fs/data/fundiff/burgers/diffusion/train_autoencoder.py", line 91, in train_and_evaluate
    for batch in train_loader:
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 732, in __next__
    data = self._next_data()
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1482, in _next_data
    idx, data = self._get_data()
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1444, in _get_data
    success, data = self._try_get_data()
  File "/root/miniconda3/envs/fundiff_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1288, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 8883, 8884, 8885, 8886, 8887, 8888, 8889, 8890) exited unexpectedly
